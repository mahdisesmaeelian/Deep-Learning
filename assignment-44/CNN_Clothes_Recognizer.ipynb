{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Clothes_Recognizer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb "
      ],
      "metadata": {
        "id": "P7nzEg4aK9DX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1R4yXkYWKz9J"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import  Conv2D,MaxPool2D,Flatten,Dense\n",
        "\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project=\"Clothes Recognizer\")"
      ],
      "metadata": {
        "id": "o0fWzFpJLDgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "jB1mVhWxQujV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/drive/MyDrive/Clothes Dataset\"\n",
        "\n",
        "width = height = 224\n",
        "\n",
        "idg = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    horizontal_flip = True,\n",
        "    rotation_range = 15,\n",
        "    zoom_range = 0.1,\n",
        "    brightness_range =  (0.9, 1.1), \n",
        "    validation_split = 0.2\n",
        ")\n",
        "\n",
        "train_data = idg.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size = (width , height),\n",
        "    class_mode = 'categorical',\n",
        "    subset = 'training'\n",
        ")\n",
        "\n",
        "val_data = idg.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size = (width , height),\n",
        "    class_mode = 'categorical',\n",
        "    subset = 'validation'\n",
        ")"
      ],
      "metadata": {
        "id": "Fkv35s9FLKHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "sxgcZHw2Qwp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    Conv2D(32 , (3,3), activation='relu', input_shape=(width, height, 3)),               \n",
        "    Conv2D(32 , (3,3), activation='relu'),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(32 , (3,3), activation='relu'),\n",
        "    Conv2D(32 , (3,3), activation='relu'),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(64 , (3,3), activation='relu'),\n",
        "    Conv2D(64 , (3,3), activation='relu'),\n",
        "    MaxPool2D(),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(4, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "kcW-4mjyLUOh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss = tf.keras.losses.categorical_crossentropy,\n",
        "              metrics =['accuracy'] )"
      ],
      "metadata": {
        "id": "uG5cIwILLWrh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "J9EL7iMqQp5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_data, validation_data= val_data, epochs=10,callbacks=[WandbCallback()])"
      ],
      "metadata": {
        "id": "-HdJrMMLLYrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "jpLRM08AQkUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/drive/MyDrive/Clothes Test\"\n",
        "\n",
        "width = height = 224\n",
        "\n",
        "idg = ImageDataGenerator(\n",
        "    rescale = 1./255\n",
        ")\n",
        "\n",
        "test_data = idg.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size = (width , height),\n",
        "    class_mode = 'categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJDbPpq2Qfyw",
        "outputId": "9892d23e-b694-4245-fda8-e3f448fe05e8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 84 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PECy-YSxQ2dF",
        "outputId": "db28a11e-4a21-4115-d844-15f8317fce14"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 13s 6s/step - loss: 1.1335 - accuracy: 0.6071\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.1335300207138062, 0.6071428656578064]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Model"
      ],
      "metadata": {
        "id": "br8ZhvNtQ5Kw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"Recognizer.h5\")"
      ],
      "metadata": {
        "id": "nFAr6olmQ7Mu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "LMEGfotlQ-FI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(\"/content/3.jpg\")\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "img = cv2.resize(img, (width, height))\n",
        "img = img / 255.0\n",
        "img = img.reshape(1, width, height, 3)\n",
        "\n",
        "result = model.predict(img)\n",
        "result\n",
        "pred = np.argmax(result)\n",
        "pred\n",
        "if pred == 0:\n",
        "  print(\"ðŸ‘œ\")\n",
        "elif pred == 1:\n",
        "  print(\"ðŸ‘ \")\n",
        "elif pred == 2:\n",
        "  print(\"ðŸ‘Ÿ\")\n",
        "elif pred == 3:\n",
        "  print(\"ðŸ§¥\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tV1mMT0AQ_4b",
        "outputId": "9044c290-0fc8-4da6-84d6-bece799c8ee0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ‘ \n"
          ]
        }
      ]
    }
  ]
}